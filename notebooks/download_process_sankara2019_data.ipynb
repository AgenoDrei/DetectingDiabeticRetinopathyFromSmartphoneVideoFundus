{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e0aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from os.path import join\n",
    "import shutil\n",
    "from scripts.legacy import frames_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "106604b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATE OF EXAMINATION', 'CAMP LOCATION', 'PATIENT ID', 'GENDER',\n",
      "       'AGE (YEARS)', 'EDUCATION', 'BP', 'RBS', 'HEIGHT (cm)', 'WEIGHT (kg)',\n",
      "       'HYPERTENSION', 'DIABETES', 'FAMILY HISTORY OF DIABETES',\n",
      "       'DURATION OF DIABETES', 'DIABETIC MEDICATION',\n",
      "       'DIABETIC MEDICATION GROUP',\n",
      "       'SYSTEMIC ABNORMALITY \\nOPTIONS- NIL, CARDIAC, NEPHROPATHY, STROKE, OTHERS',\n",
      "       'RE VISUAL ACUITY', 'LE VISUAL ACUITY', 'RE LENS STATUS',\n",
      "       'LE LENS STATUS', 'RE PAXOSCOPE MACULA CENTRED IMAGE UPLOAD',\n",
      "       'RE PAXOS DISC CENTRED IMAGE UPLOAD', 'RE PAXOS TEMPORAL IMAGE UPLOAD',\n",
      "       'RE PAXOS STQ IMAGE UPLOAD', 'RE PAXOS ITQ IMAGE UPLOAD',\n",
      "       'RE PAXOS SNQ IMAGE UPLOAD', 'RE PAXOS INQ IMAGE UPLOAD',\n",
      "       'RE PAXOS OTHER IMAGES UPLOAD',\n",
      "       'LE PAXOSCOPE MACULA CENTRED IMAGE UPLOAD',\n",
      "       'LE PAXOS DISC CENTRED IMAGE UPLOAD', 'LE PAXOS TEMPORAL IMAGE UPLOAD',\n",
      "       'LE PAXOS STQ IMAGE UPLOAD', 'LE PAXOS ITQ IMAGE UPLOAD',\n",
      "       'LE PAXOS SNQ IMAGE UPLOAD', 'LE PAXOS INQ IMAGE UPLOAD',\n",
      "       'LE PAXOS OTHER IMAGES UPLOAD',\n",
      "       'OPTOMETRIST \\nRE :  DR GRADE - PAXOSCOPE POST-DILATION',\n",
      "       'OPTOMETRIST LE :  DR GRADE - PAXOSCOPE POST-DILATION',\n",
      "       'OPTOMETRIST \\nRE  DME - PAXOSCOPE',\n",
      "       'OPTOMETRIST \\nLE  DME - PAXOSCOPE',\n",
      "       'OPTOMETRIST \\nRE REFERRABLE DR - PAXOSCOPE',\n",
      "       'OPTOMETRIST \\nLE REFERRABLE DR - PAXOSCOPE',\n",
      "       'RE DR GRADE - DOCTOR AT CAMP', 'LE DR GRADE - \\nDOCTOR AT CAMP',\n",
      "       'Ophthalmologist\\nRE TELEGRADING', 'Ophthalmologist\\nLE TELEGRADING'],\n",
      "      dtype='object')\n",
      "Dataset length: 335\n"
     ]
    }
   ],
   "source": [
    "root_folder = \"C:/Users/Simon/Data/BOON DR CAMP PROJECT 2019-2021/\"\n",
    "sorted_dir = join(root_folder, \"02_sorted_by_eye_pp/\")\n",
    "renamed_dir = join(root_folder, \"03_renamed_and_sorted_pp\")\n",
    "created_folders = os.listdir(sorted_dir)\n",
    "OPT_RE = 'OPTOMETRIST \\nRE :  DR GRADE - PAXOSCOPE POST-DILATION'\n",
    "OPT_LE = 'OPTOMETRIST LE :  DR GRADE - PAXOSCOPE POST-DILATION'\n",
    "OPH_RE = 'Ophthalmologist\\nRE TELEGRADING'\n",
    "OPH_LE = 'Ophthalmologist\\nLE TELEGRADING'\n",
    "\n",
    "df = pd.read_excel(join(root_folder, \"BOON DR CAMP PROJECT 2019-2021_preparation for R 1.1.xlsx\"))\n",
    "df = df.drop(df.columns[-29:],axis=1)\n",
    "print(df.columns)\n",
    "print(f'Dataset length: {len(df)}')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daaea53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset length: 223\n"
     ]
    }
   ],
   "source": [
    "# Remove empty rows\n",
    "'''df_data = df.loc[1:, ['PATIENT ID','RE PAXOSCOPE MACULA CENTRED IMAGE UPLOAD',\n",
    "       'RE PAXOS DISC CENTRED IMAGE UPLOAD', 'RE PAXOS TEMPORAL IMAGE UPLOAD',\n",
    "       'RE PAXOS STQ IMAGE UPLOAD', 'RE PAXOS ITQ IMAGE UPLOAD',\n",
    "       'RE PAXOS SNQ IMAGE UPLOAD', 'RE PAXOS INQ IMAGE UPLOAD',\n",
    "       'RE PAXOS OTHER IMAGES UPLOAD',\n",
    "       'LE PAXOSCOPE MACULA CENTRED IMAGE UPLOAD',\n",
    "       'LE PAXOS DISC CENTRED IMAGE UPLOAD', 'LE PAXOS TEMPORAL IMAGE UPLOAD',\n",
    "       'LE PAXOS STQ IMAGE UPLOAD', 'LE PAXOS ITQ IMAGE UPLOAD',\n",
    "       'LE PAXOS SNQ IMAGE UPLOAD', 'LE PAXOS INQ IMAGE UPLOAD',\n",
    "       'LE PAXOS OTHER IMAGES UPLOAD']]'''\n",
    "\n",
    "df_data = df.loc[1:, :]\n",
    "df_data = df_data.drop(df_data[df_data['RE PAXOSCOPE MACULA CENTRED IMAGE UPLOAD'] == '[]'].index)\n",
    "df_data = df_data.drop(df_data[df_data['RE PAXOSCOPE MACULA CENTRED IMAGE UPLOAD'] == 'null'].index)\n",
    "df_data = df_data[(df_data['RE PAXOSCOPE MACULA CENTRED IMAGE UPLOAD'].notna() | df_data['LE PAXOSCOPE MACULA CENTRED IMAGE UPLOAD'].notna())]\n",
    "#df_data.tail()\n",
    "print(f'Cleaned dataset length: {len(df_data)}')\n",
    "df_data.to_excel(join(root_folder, \"BOON DR CAMP PROJECT 2019-2021 cleaned 1.1.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f347f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e96ed4202ba47eca9f09e3404e74a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/219 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download from https://teleopticsapp.s3.ap-south-1.amazonaws.com/CZ20211022003/RE/POST/REPOSTMC_20211024_237.jpg\n"
     ]
    }
   ],
   "source": [
    "# attempt to download data from aws\n",
    "base_url = 'https://teleopticsapp.s3.ap-south-1.amazonaws.com/'\n",
    "base_folder = 'aws'\n",
    "failed_attempts = 0\n",
    "\n",
    "if not os.path.exists(base_folder):\n",
    "    os.mkdir(base_folder)\n",
    "\n",
    "for i, row in tqdm(df_data.iterrows(), total=len(df_data)):\n",
    "    if row['RE PAXOSCOPE MACULA CENTRED IMAGE UPLOAD'][0] != '[':\n",
    "        # skip locally saved files\n",
    "        continue\n",
    "    url_list = eval(row['RE PAXOSCOPE MACULA CENTRED IMAGE UPLOAD'])\n",
    "    for url in url_list:\n",
    "        res = requests.get(url)\n",
    "        img_data = res.content\n",
    "        file_name = url.replace(base_url, '')\n",
    "        file_name = file_name.replace('/', '_')\n",
    "        if not res.ok:\n",
    "            print(f'Failed download from {url}')\n",
    "            failed_attempts += 1\n",
    "        else: \n",
    "            with open(os.path.join(base_folder, file_name), 'wb') as h:\n",
    "                h.write(img_data)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e32de8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/223 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53b3773e921e45f3b530129f5f03721d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflicting grading for 17, 191215004Z, right eye: /MODERATE NPDR\n",
      "Conflicting grading for 17, 191215004Z, left eye: SEVERE NPDR/MODERATE NPDR\n",
      "Conflicting grading for 18, 191215005VS, right eye: NO DR/MILD NPDR\n",
      "Conflicting grading for 19, 191215006GJ, right eye: MODERATE NPDR/MILD NPDR\n",
      "Conflicting grading for 20, 191215008AA, right eye: NO DR/\n",
      "Conflicting grading for 23, 191215011, left eye: /NO DR\n",
      "Conflicting grading for 26, 191220001RM, left eye: Moderate NPDR/MILD NPDR\n",
      "Conflicting grading for 27, 191220002BSR, right eye: NO DR/\n",
      "Conflicting grading for 34, DR270120001A, right eye: mild NPDR/NO DR\n",
      "Conflicting grading for 44, 120120008SK, right eye: NO DR/MILD NPDR\n",
      "Conflicting grading for 45, 02022002PA, left eye: NO DR/MILD NPDR\n",
      "Conflicting grading for 46, 020220001KA, right eye: MILD NPDR/MODERATE NPDR\n",
      "Conflicting grading for 56, 220220001PR, right eye: SEVERE NPDR/MODERATE NPDR\n",
      "Conflicting grading for 56, 220220001PR, left eye: SEVERE NPDR/MODERATE NPDR\n",
      "Conflicting grading for 60, 280220001PR, right eye: No DR/MILD NPDR\n",
      "Conflicting grading for 62, 280220003RR, right eye: NO DR/MODERATE NPDR\n",
      "Conflicting grading for 71, 1311200002, left eye: NO DR/MILD NPDR\n",
      "Conflicting grading for 81, 160421003, right eye: Moderate NPDR/NO DR\n",
      "Conflicting grading for 81, 160421003, left eye: Moderate NPDR/NO DR\n"
     ]
    }
   ],
   "source": [
    "# Check whether tele-opthmologists and optometrist grading is the same\n",
    "df_data = df_data.replace('CANT GRADE ', '')\n",
    "df_data = df_data.replace('CANNOT COMMENT', '')\n",
    "\n",
    "for i, row in tqdm(df_data.iterrows(), total=len(df_data)):\n",
    "    if pd.isna(row[OPT_RE]) or pd.isna(row[OPH_RE]):\n",
    "        pass\n",
    "    elif not row[OPT_RE].split(' ')[0].lower() == row[OPH_RE].split(' ')[0].lower():\n",
    "        print(f\"Conflicting grading for {i}, {row['PATIENT ID']}, right eye: {row[OPT_RE]}/{row[OPH_RE]}\")\n",
    "    if pd.isna(row[OPT_LE]) or pd.isna(row[OPH_LE]):\n",
    "        pass\n",
    "    elif not row[OPT_LE].split(' ')[0].lower() == row[OPH_LE].split(' ')[0].lower():\n",
    "        print(f\"Conflicting grading for {i}, {row['PATIENT ID']}, left eye: {row[OPT_LE]}/{row[OPH_LE]}\")\n",
    "\n",
    "# 81, 160421003 -> NO DR\n",
    "# 71, 1311200002 -> NO DR\n",
    "# 62, 280220003RR -> MODERATE NPDR\n",
    "# 60, 280220001PR -> MILD NPDR\n",
    "# 56, 220220001PR -> MODERATE NPDR\n",
    "# 46, 020220001KA -> MODERATE NPDR\n",
    "# 45, 02022002PA -> MILD NPDR\n",
    "# 44, 120120008SK -> MILD NPDR\n",
    "# 34, DR270120001A -> MILD NPDR\n",
    "# 27, 191220002BSR -> NO DR\n",
    "# 26, 191220001RM -> MILD NPDR\n",
    "# 23, 191215011 -> CANNOT COMMENT\n",
    "# 19, 191215006GJ -> MILD NPDR\n",
    "# 18, 191215005VS -> NO DR/MILD NPDR\n",
    "# 17, 191215004Z -> RE: CANNOT COMMENT, LE: MODERATE NPDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84baac1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/223 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c157fdff4009416c8a62b6887cc1167a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 emtpy folders were removed after population\n"
     ]
    }
   ],
   "source": [
    "# Move images to examination folder according to excel file\n",
    "dir_name = join(root_folder, \"02_sorted_by_eye_pp/\")\n",
    "lookup_folder = '01_images_pp' # for non-processed images'SANKARA UKB DR STUDY_Images'\n",
    "right_eye_cols = ['RE PAXOSCOPE MACULA CENTRED IMAGE UPLOAD','RE PAXOS DISC CENTRED IMAGE UPLOAD', 'RE PAXOS TEMPORAL IMAGE UPLOAD',\n",
    "       'RE PAXOS STQ IMAGE UPLOAD', 'RE PAXOS ITQ IMAGE UPLOAD', 'RE PAXOS SNQ IMAGE UPLOAD', 'RE PAXOS INQ IMAGE UPLOAD',\n",
    "       'RE PAXOS OTHER IMAGES UPLOAD']\n",
    "left_eye_cols = ['LE PAXOSCOPE MACULA CENTRED IMAGE UPLOAD', 'LE PAXOS DISC CENTRED IMAGE UPLOAD', 'LE PAXOS TEMPORAL IMAGE UPLOAD',\n",
    "       'LE PAXOS STQ IMAGE UPLOAD', 'LE PAXOS ITQ IMAGE UPLOAD', 'LE PAXOS SNQ IMAGE UPLOAD', 'LE PAXOS INQ IMAGE UPLOAD',\n",
    "       'LE PAXOS OTHER IMAGES UPLOAD']\n",
    "\n",
    "if os.path.exists(dir_name):\n",
    "    shutil.rmtree(dir_name)\n",
    "os.mkdir(dir_name)\n",
    "for i, row in tqdm(df_data.iterrows(), total=len(df_data)):\n",
    "    pid = row['PATIENT ID']\n",
    "    if i > 82:\n",
    "        continue\n",
    "    dir_le, dir_re = join(dir_name, str(pid) + '_LE'), join(dir_name, str(pid) + '_RE')\n",
    "    os.mkdir(dir_le)\n",
    "    os.mkdir(dir_re)\n",
    "    \n",
    "    for j, col in enumerate(right_eye_cols):\n",
    "        if not pd.isna(row[col]): \n",
    "            row[col] = join(lookup_folder, row[col].split('/')[1])\n",
    "        if not pd.isna(row[col]) and os.path.exists(join(root_folder, row[col])):\n",
    "            shutil.copy(join(root_folder, row[col]), join(dir_re, os.path.basename(row[col])))\n",
    "    for j, col in enumerate(left_eye_cols):\n",
    "        if not pd.isna(row[col]):\n",
    "            row[col] = join(lookup_folder, row[col].split('/')[1])\n",
    "        if not pd.isna(row[col]) and os.path.exists(join(root_folder, row[col])):\n",
    "            shutil.copy(join(root_folder, row[col]), join(dir_le, os.path.basename(row[col])))\n",
    "\n",
    "created_folders = os.listdir(dir_name)\n",
    "deletions = 0\n",
    "for folder in created_folders:\n",
    "    if len(os.listdir(join(dir_name, folder))) == 0:\n",
    "        os.rmdir(join(dir_name, folder))\n",
    "        deletions += 1\n",
    "print(f'{deletions} emtpy folders were removed after population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbf99b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate filenames to Paxos nomentclature: ([A-Z])(\\d){3}[RL](\\d)?\n",
    "camp_prefix = 'X'\n",
    "os.mkdir(renamed_dir)\n",
    "count = 0\n",
    "seen = {}\n",
    "for i, folder in enumerate(created_folders):\n",
    "    old_count, count_flag = -1, False\n",
    "    if folder.split('_')[0] not in seen.keys():\n",
    "        count += 1\n",
    "        seen[folder.split('_')[0]] = count\n",
    "    else:\n",
    "        count = seen[folder.split('_')[0]]\n",
    "        old_count = count\n",
    "        count_flag = True\n",
    "\n",
    "    suffix = folder.split('_')[1][0]\n",
    "    exam_id = f'{camp_prefix}{count:03d}{suffix}'\n",
    "    os.mkdir(join(renamed_dir, exam_id))\n",
    "\n",
    "    for j, img in enumerate(os.listdir(join(sorted_dir, folder))):\n",
    "        shutil.copy(join(sorted_dir, folder, img), join(renamed_dir, exam_id, f'{exam_id}_{j:02d}{os.path.splitext(img)[1]}'))\n",
    "        # Copy file just into the root folder\n",
    "        shutil.copy(join(sorted_dir, folder, img), join(renamed_dir, f'{exam_id}_{j:02d}{os.path.splitext(img)[1]}'))\n",
    "    with open(join(renamed_dir, exam_id, 'legacy.txt'), \"w\") as f:\n",
    "        f.write(folder)\n",
    "    if count_flag:\n",
    "        count = old_count\n",
    "        count_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec5cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1200 files\n",
    "# 1171 lose 30 files through cropping\n",
    "# 823 lose 340 files which are not mentioned in the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/957 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c19580bba9e448fb91954cad0c3d0b93"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create label file (Map new_id to old_id labeling info, copy relevant labels)\n",
    "df_labels = pd.DataFrame(columns=['image', 'level', 'optometrist_rating', 'ophthalmologist_rating'])\n",
    "df_labels_exams = pd.DataFrame(columns=['image', 'level', 'optometrist_rating', 'ophthalmologist_rating'])\n",
    "for i, folder in tqdm(enumerate(os.listdir(renamed_dir)), total=len(os.listdir(renamed_dir))):\n",
    "    if not os.path.exists(join(renamed_dir, folder, 'legacy.txt')):\n",
    "        continue\n",
    "    with open(join(renamed_dir, folder, 'legacy.txt'), 'r') as f:\n",
    "        old_id = f.read()\n",
    "        if len(old_id) > 0:\n",
    "            old_id = old_id.split('_')[0]\n",
    "\n",
    "    corres_row = df_data.loc[df_data['PATIENT ID'] == old_id].to_dict()\n",
    "    #print(old_id, list(corres_row[OPT_LE].values())[0],  corres_row[OPT_RE],  corres_row[OPH_LE],  corres_row[OPH_RE])\n",
    "    face_side = folder[-1]\n",
    "    new_entry = {'optometrist_rating': None, 'ophthalmologist_rating': None, 'level': None, 'image': None}\n",
    "    for img_path in os.listdir(join(renamed_dir, folder)):\n",
    "        if img_path == 'legacy.txt':\n",
    "            continue\n",
    "        if face_side == 'L':\n",
    "            opt = OPT_LE\n",
    "            oph = OPH_LE\n",
    "        elif face_side == 'R':\n",
    "            opt = OPT_RE\n",
    "            oph = OPH_RE\n",
    "        else:\n",
    "            oph, opt = None, None\n",
    "        # print(old_id, face_side, corres_row[opt].values())\n",
    "        if len(list(corres_row[opt].values())) > 0:\n",
    "            new_entry['optometrist_rating'] = list(corres_row[opt].values())[0]\n",
    "            if type(new_entry['optometrist_rating']) == str:\n",
    "                new_entry['optometrist_rating'] = new_entry['optometrist_rating'].lower()\n",
    "        if len(list(corres_row[opt].values())) > 0:\n",
    "            new_entry['ophthalmologist_rating'] = list(corres_row[oph].values())[0]\n",
    "            if type(new_entry['ophthalmologist_rating']) == str:\n",
    "                new_entry['ophthalmologist_rating'] = new_entry['ophthalmologist_rating'].lower()\n",
    "        #if new_entry['ophthalmologist_rating'] == new_entry['optometrist_rating']:\n",
    "        if new_entry['ophthalmologist_rating']:\n",
    "            new_entry['level'] = new_entry['ophthalmologist_rating']\n",
    "        elif new_entry['optometrist_rating']:\n",
    "            new_entry['level'] = new_entry['optometrist_rating']\n",
    "        new_entry['image'] = img_path\n",
    "\n",
    "        df_labels = df_labels.append(new_entry, ignore_index=True)\n",
    "    df_labels_exams = df_labels_exams.append({'image': folder, 'level': new_entry['level']}, ignore_index=True)\n",
    "\n",
    "df_labels.to_csv(join(root_folder, renamed_dir, 'labels_renamed.csv'), index=False)\n",
    "df_labels_exams.to_csv(join(root_folder, renamed_dir, 'labels_exam_renamed.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Process images from AWS cloud\n",
    "additional_labels = join(root_folder, 'UPDATED DR GRADING BONN PROJECT.xlsx')\n",
    "raw_data = join(root_folder, 'SANKARA UKB DR STUDY_aws/')\n",
    "preprocessed_data = join(root_folder, '01_images_aws/')\n",
    "cropped_data = join(root_folder, '02_images_aws_pp/')\n",
    "sorted_data = join(root_folder, '03_images_aws_pp_sorted/')\n",
    "renamed_data = join(root_folder, '04_images_aws_pp_renamed/')\n",
    "first_index =  71\n",
    "\n",
    "if not os.path.exists(preprocessed_data):\n",
    "    os.mkdir(preprocessed_data)\n",
    "    for f in tqdm(os.listdir(raw_data), total=len(os.listdir(raw_data))):\n",
    "        img = cv2.imread(join(raw_data, f))\n",
    "        if img.shape[0] < 3000:\n",
    "            shutil.copy(join(raw_data, f), join(preprocessed_data, f))\n",
    "            continue\n",
    "        img = cv2.resize(img, dsize=None, fx=0.4, fy=0.4)\n",
    "        cv2.imwrite(join(preprocessed_data, f), img)\n",
    "\n",
    "if not os.path.exists(cropped_data):\n",
    "    os.mkdir(cropped_data)\n",
    "    frames_preprocess.run(preprocessed_data, cropped_data, min_radius=350)\n",
    "\n",
    "folders = []\n",
    "if not os.path.exists(sorted_data):\n",
    "    os.mkdir(sorted_data)\n",
    "    for i, f in enumerate(os.listdir(cropped_data)):\n",
    "        img_id = f.split('_')[0]\n",
    "        suffix = f.split('_')[1][0]\n",
    "        exam_id = f'{img_id}_{suffix}'\n",
    "\n",
    "        if exam_id in folders:\n",
    "            shutil.copy(join(cropped_data, f), join(sorted_data, exam_id, f))\n",
    "        else:\n",
    "            os.mkdir(join(sorted_data, exam_id))\n",
    "            shutil.copy(join(cropped_data, f), join(sorted_data, exam_id, f))\n",
    "            folders.append(exam_id)\n",
    "\n",
    "cur_index = first_index\n",
    "if not os.path.exists(renamed_data):\n",
    "    os.mkdir(renamed_data)\n",
    "    for i, folder in enumerate(os.listdir(sorted_data)):\n",
    "        suffix = folder.split('_')[1]\n",
    "        exam_id = f'{camp_prefix}{cur_index:03d}{suffix}'\n",
    "        os.mkdir(join(renamed_data, exam_id))\n",
    "\n",
    "        for j, img in enumerate(os.listdir(join(sorted_data, folder))):\n",
    "            shutil.copy(join(sorted_data, folder, img), join(renamed_data, exam_id, f'{exam_id}_{j:02d}{os.path.splitext(img)[1]}'))\n",
    "            # Copy file just into the root folder\n",
    "            shutil.copy(join(sorted_data, folder, img), join(renamed_data, f'{exam_id}_{j:02d}{os.path.splitext(img)[1]}'))\n",
    "        with open(join(renamed_data, exam_id, 'legacy.txt'), \"w\") as f:\n",
    "            f.write(folder)\n",
    "        cur_index += 1\n",
    "\n",
    "    #create lables file\n",
    "    ref_df = pd.read_excel(additional_labels)\n",
    "    aws_df = pd.DataFrame(columns=['image', 'level', 'optometrist_rating', 'ophthalmologist_rating'])\n",
    "    for i, folder in enumerate(os.listdir(renamed_data)):\n",
    "        if not os.path.exists(join(renamed_data, folder, 'legacy.txt')):\n",
    "            continue\n",
    "        with open(join(renamed_data, folder, 'legacy.txt'), 'r') as f:\n",
    "            old_id = f.read()\n",
    "            if len(old_id) > 0:\n",
    "                old_id = old_id.split('_')[0]\n",
    "        corres_row = ref_df.loc[ref_df['PATIENT ID'] == old_id].to_dict()\n",
    "        face_side = folder[-1]\n",
    "        aws_df = aws_df.append({\n",
    "            'image': folder,\n",
    "            'level': list(corres_row['LE TELEGRADING' if face_side == 'L' else 'RE TELEGRADING'].values())[0]\n",
    "        }, ignore_index=True)\n",
    "    aws_df.to_csv(join(root_folder, renamed_data, 'labels_aws_renamed.csv'), index=False)\n",
    "\n",
    "\n",
    "# RE TELEGRADING\tLE TELEGRADING"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Combined aws and hard-drive images in one dataset\n",
    "combined_dir = join(root_folder, '05_images_pp_renamed_combined')\n",
    "# os.mkdir(combined_dir)\n",
    "if not os.path.exists(combined_dir):\n",
    "    shutil.copytree(renamed_dir, combined_dir, copy_function = shutil.copy)\n",
    "    shutil.copytree(renamed_data, combined_dir, copy_function = shutil.copy, dirs_exist_ok=True)\n",
    "\n",
    "df_aws = pd.read_csv(join(root_folder, combined_dir, 'labels_aws_renamed.csv'))\n",
    "df_hdd = pd.read_csv(join(root_folder, combined_dir, 'labels_exam_renamed.csv'))\n",
    "df_combined = pd.concat([df_hdd, df_aws], ignore_index=True)\n",
    "df_combined = df_combined.drop(df_combined[(df_combined.level == 'POOR QUALITY') | (df_combined.level == 'NO MEDIA')].index)\n",
    "df_combined.to_csv(join(root_folder, combined_dir, 'labels_combined.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}